{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Quadruple N\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "import pandas_datareader as pdr\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('tablet10101.csv', index_col=0)\n",
    "df2 = pd.read_csv('spq.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['T10101', 'T10102', 'T10103', 'T10104', 'T10105', 'T10106', 'T10107', 'T10108', 'T10109', 'T10110', 'T10111', 'T10201', 'T10202', 'T10203', 'T10204', 'T10205', 'T10206', 'T10301', 'T10303', 'T10304', 'T10305', 'T10306', 'T10401', 'T10403', 'T10404', 'T10405', 'T10406', 'T10501', 'T10502', 'T10503', 'T10504', 'T10505', 'T10506', 'T10604', 'T10607', 'T10608', 'T10701', 'T10703', 'T10704', 'T10705', 'T10706', 'T10803', 'T10806', 'T10903', 'T10904', 'T10905', 'T10906', 'T11000', 'T11100', 'T11200', 'T11300', 'T11400', 'T11500', 'T11600', 'T11701', 'T11705', 'T11706', 'T20100', 'T20200A', 'T20200B', 'T20301', 'T20302', 'T20303', 'T20304', 'T20305', 'T20306', 'T20307', 'T20403', 'T20404', 'T20405', 'T20406', 'T20503', 'T20504', 'T20505', 'T20506', 'T20600', 'T20700A', 'T20700B', 'T20801', 'T20803', 'T20804', 'T20805', 'T20806', 'T20807', 'T30100', 'T30200', 'T30300', 'T30400', 'T30500', 'T30600', 'T30700', 'T30800', 'T30901', 'T30902', 'T30903', 'T30904', 'T30905', 'T30906', 'T31001', 'T31003', 'T31004', 'T31005', 'T31006', 'T31101', 'T31102', 'T31103', 'T31104', 'T31105', 'T31106', 'T31200', 'T31300', 'T31400', 'T40100', 'T40201', 'T40202', 'T40203', 'T40204', 'T40205', 'T40206', 'T4030A', 'T4030B', 'T4030C', 'T50100', 'T50203', 'T50205', 'T50206', 'T50301', 'T50302', 'T50303', 'T50304', 'T50305', 'T50306', 'T50401', 'T50402', 'T50403', 'T50404', 'T50405', 'T50406', 'T50501', 'T50502', 'T50503', 'T50504', 'T50505', 'T50506', 'T50601', 'T50602', 'T50603', 'T50604', 'T50605', 'T50606', 'T50705A', 'T50705B', 'T50706A', 'T50706B', 'T50805A', 'T50805B', 'T50806A', 'T50806B', 'T50809A', 'T50809B', 'T50903', 'T50904', 'T50905', 'T50906', 'T51100', 'T60100B', 'T60100C', 'T60100D', 'T60200A', 'T60200B', 'T60200C', 'T60200D', 'T60300A', 'T60300B', 'T60300C', 'T60300D', 'T60400A', 'T60400B', 'T60400C', 'T60400D', 'T60500A', 'T60500B', 'T60500C', 'T60500D', 'T60600A', 'T60600B', 'T60600C', 'T60600D', 'T60700A', 'T60700B', 'T60700C', 'T60700D', 'T60800A', 'T60800B', 'T60800C', 'T60800D', 'T60900B', 'T60900C', 'T60900D', 'T61000B', 'T61000C', 'T61000D', 'T61100A', 'T61100B', 'T61100C', 'T61100D', 'T61200A', 'T61200B', 'T61200C', 'T61200D', 'T61300A', 'T61300B', 'T61300C', 'T61300D', 'T61400A', 'T61400B', 'T61400C', 'T61400D', 'T61500A', 'T61500B', 'T61500C', 'T61500D', 'T61600A', 'T61600B', 'T61600C', 'T61600D', 'T61700A', 'T61700B', 'T61700C', 'T61700D', 'T61800A', 'T61800B', 'T61800C', 'T61800D', 'T61900A', 'T61900B', 'T61900C', 'T61900D', 'T62000A', 'T62000B', 'T62000C', 'T62000D', 'T62100A', 'T62100B', 'T62100C', 'T62100D', 'T62200A', 'T62200B', 'T62200C', 'T62200D', 'T70100', 'T70201A', 'T70201B', 'T70203A', 'T70203B', 'T70204A', 'T70204B', 'T70205A', 'T70205B', 'T70206B', 'T70303', 'T70304', 'T70305', 'T70306', 'T70403', 'T70404', 'T70405', 'T70406', 'T70500', 'T70600', 'T70700', 'T70800', 'T70900', 'T71000', 'T71100', 'T71200', 'T71300', 'T71400', 'T71500', 'T71600', 'T71700', 'T71800', 'T72000', 'T72100', 'T72200', 'T72300', 'T72400', 'T72500', 'T80103', 'T80104', 'T80105', 'T80106', 'T80111', 'T80200', 'T80300', 'T80400'])\n"
     ]
    }
   ],
   "source": [
    "def readFiles(filename):\n",
    "    df = pd.read_csv(str(filename+'.csv'), index_col=0)\n",
    "    return df\n",
    "\n",
    "filelist = pd.read_csv('listnames.csv')\n",
    "dfs = {}\n",
    "for x in filelist['0']:\n",
    "    dfs[x] = readFiles(x)\n",
    "print(dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 159, 293, 296, 297, 55, 196, 197, 73, 203, 77, 78, 79, 80, 81, 215, 216, 89, 217, 97, 98}\n"
     ]
    }
   ],
   "source": [
    "samelen = {}\n",
    "lens = set()\n",
    "for x in dfs:\n",
    "    lens.add(len(dfs[x]))\n",
    "print(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294\n"
     ]
    }
   ],
   "source": [
    "X = df1.iloc[1:-1, :]\n",
    "df2 = df2.iloc[1:,:]\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294\n"
     ]
    }
   ],
   "source": [
    "Y = df2['Adj Close'].apply(lambda x: 1 if x > 0 else 0).shift(-1)\n",
    "Y = Y.iloc[:-1]\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = StandardScaler().fit_transform(X)\n",
    "y = Y.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "235/235 [==============================] - 3s 12ms/step - loss: 0.8357 - acc: 0.4170\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8294 - acc: 0.4128\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 0s 871us/step - loss: 0.8233 - acc: 0.4170\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 0s 930us/step - loss: 0.8174 - acc: 0.4170\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8117 - acc: 0.4128\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8057 - acc: 0.4170\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.8003 - acc: 0.4298\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7950 - acc: 0.4426\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7899 - acc: 0.4426\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7851 - acc: 0.4383\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7801 - acc: 0.4426\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7753 - acc: 0.4383\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7708 - acc: 0.4340\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7665 - acc: 0.4298\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7623 - acc: 0.4383\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7577 - acc: 0.4383\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7536 - acc: 0.4426\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.7497 - acc: 0.4383\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7458 - acc: 0.4426\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7423 - acc: 0.4426\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 0s 820us/step - loss: 0.7388 - acc: 0.4553\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 0s 766us/step - loss: 0.7354 - acc: 0.4511\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7320 - acc: 0.4638\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 0s 989us/step - loss: 0.7288 - acc: 0.4681\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7256 - acc: 0.4851\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7228 - acc: 0.4894\n",
      "Epoch 27/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7198 - acc: 0.5021\n",
      "Epoch 28/100\n",
      "235/235 [==============================] - 0s 861us/step - loss: 0.7168 - acc: 0.5064\n",
      "Epoch 29/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.7139 - acc: 0.5064\n",
      "Epoch 30/100\n",
      "235/235 [==============================] - 0s 783us/step - loss: 0.7111 - acc: 0.5064\n",
      "Epoch 31/100\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.7087 - acc: 0.5106\n",
      "Epoch 32/100\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.7063 - acc: 0.5106\n",
      "Epoch 33/100\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.7037 - acc: 0.5149\n",
      "Epoch 34/100\n",
      "235/235 [==============================] - 0s 814us/step - loss: 0.7016 - acc: 0.5191\n",
      "Epoch 35/100\n",
      "235/235 [==============================] - 0s 832us/step - loss: 0.6993 - acc: 0.5319\n",
      "Epoch 36/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6971 - acc: 0.5404\n",
      "Epoch 37/100\n",
      "235/235 [==============================] - 0s 927us/step - loss: 0.6951 - acc: 0.5404\n",
      "Epoch 38/100\n",
      "235/235 [==============================] - 0s 987us/step - loss: 0.6930 - acc: 0.5489\n",
      "Epoch 39/100\n",
      "235/235 [==============================] - 0s 909us/step - loss: 0.6909 - acc: 0.5574\n",
      "Epoch 40/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6891 - acc: 0.5872\n",
      "Epoch 41/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6871 - acc: 0.5915\n",
      "Epoch 42/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6852 - acc: 0.5915\n",
      "Epoch 43/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6835 - acc: 0.6043\n",
      "Epoch 44/100\n",
      "235/235 [==============================] - 0s 954us/step - loss: 0.6819 - acc: 0.6128\n",
      "Epoch 45/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6802 - acc: 0.6170\n",
      "Epoch 46/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6787 - acc: 0.6255\n",
      "Epoch 47/100\n",
      "235/235 [==============================] - 0s 976us/step - loss: 0.6772 - acc: 0.6255\n",
      "Epoch 48/100\n",
      "235/235 [==============================] - 0s 791us/step - loss: 0.6758 - acc: 0.6213\n",
      "Epoch 49/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6745 - acc: 0.6340\n",
      "Epoch 50/100\n",
      "235/235 [==============================] - 0s 973us/step - loss: 0.6731 - acc: 0.6383\n",
      "Epoch 51/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6720 - acc: 0.6468\n",
      "Epoch 52/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6709 - acc: 0.6468\n",
      "Epoch 53/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6697 - acc: 0.6511\n",
      "Epoch 54/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6686 - acc: 0.6511\n",
      "Epoch 55/100\n",
      "235/235 [==============================] - 0s 901us/step - loss: 0.6676 - acc: 0.6553\n",
      "Epoch 56/100\n",
      "235/235 [==============================] - 0s 834us/step - loss: 0.6664 - acc: 0.6596\n",
      "Epoch 57/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6655 - acc: 0.6596\n",
      "Epoch 58/100\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.6645 - acc: 0.6638\n",
      "Epoch 59/100\n",
      "235/235 [==============================] - 0s 804us/step - loss: 0.6637 - acc: 0.6723\n",
      "Epoch 60/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6627 - acc: 0.6723\n",
      "Epoch 61/100\n",
      "235/235 [==============================] - 0s 788us/step - loss: 0.6618 - acc: 0.6681\n",
      "Epoch 62/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6608 - acc: 0.6681\n",
      "Epoch 63/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6602 - acc: 0.6638\n",
      "Epoch 64/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6591 - acc: 0.6638\n",
      "Epoch 65/100\n",
      "235/235 [==============================] - 0s 999us/step - loss: 0.6583 - acc: 0.6638\n",
      "Epoch 66/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6575 - acc: 0.6638\n",
      "Epoch 67/100\n",
      "235/235 [==============================] - 0s 871us/step - loss: 0.6568 - acc: 0.6638\n",
      "Epoch 68/100\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.6561 - acc: 0.6638\n",
      "Epoch 69/100\n",
      "235/235 [==============================] - 0s 770us/step - loss: 0.6553 - acc: 0.6638\n",
      "Epoch 70/100\n",
      "235/235 [==============================] - 0s 790us/step - loss: 0.6547 - acc: 0.6638\n",
      "Epoch 71/100\n",
      "235/235 [==============================] - 0s 851us/step - loss: 0.6539 - acc: 0.6638\n",
      "Epoch 72/100\n",
      "235/235 [==============================] - 0s 699us/step - loss: 0.6534 - acc: 0.6638\n",
      "Epoch 73/100\n",
      "235/235 [==============================] - 0s 768us/step - loss: 0.6527 - acc: 0.6638\n",
      "Epoch 74/100\n",
      "235/235 [==============================] - 0s 857us/step - loss: 0.6522 - acc: 0.6638\n",
      "Epoch 75/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6516 - acc: 0.6638\n",
      "Epoch 76/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6510 - acc: 0.6638\n",
      "Epoch 77/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6505 - acc: 0.6638\n",
      "Epoch 78/100\n",
      "235/235 [==============================] - 0s 917us/step - loss: 0.6500 - acc: 0.6596\n",
      "Epoch 79/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6496 - acc: 0.6596\n",
      "Epoch 80/100\n",
      "235/235 [==============================] - 0s 953us/step - loss: 0.6490 - acc: 0.6596\n",
      "Epoch 81/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6485 - acc: 0.6596\n",
      "Epoch 82/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6481 - acc: 0.6596\n",
      "Epoch 83/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6475 - acc: 0.6553\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6471 - acc: 0.6553\n",
      "Epoch 85/100\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6466 - acc: 0.6596\n",
      "Epoch 86/100\n",
      "235/235 [==============================] - 0s 977us/step - loss: 0.6461 - acc: 0.6596\n",
      "Epoch 87/100\n",
      "235/235 [==============================] - 0s 854us/step - loss: 0.6457 - acc: 0.6596\n",
      "Epoch 88/100\n",
      "235/235 [==============================] - 0s 784us/step - loss: 0.6452 - acc: 0.6596\n",
      "Epoch 89/100\n",
      "235/235 [==============================] - 0s 753us/step - loss: 0.6449 - acc: 0.6596\n",
      "Epoch 90/100\n",
      "235/235 [==============================] - 0s 751us/step - loss: 0.6445 - acc: 0.6596\n",
      "Epoch 91/100\n",
      "235/235 [==============================] - 0s 805us/step - loss: 0.6442 - acc: 0.6596\n",
      "Epoch 92/100\n",
      "235/235 [==============================] - 0s 774us/step - loss: 0.6439 - acc: 0.6596\n",
      "Epoch 93/100\n",
      "235/235 [==============================] - 0s 766us/step - loss: 0.6436 - acc: 0.6596\n",
      "Epoch 94/100\n",
      "235/235 [==============================] - 0s 781us/step - loss: 0.6431 - acc: 0.6596\n",
      "Epoch 95/100\n",
      "235/235 [==============================] - 0s 716us/step - loss: 0.6428 - acc: 0.6596\n",
      "Epoch 96/100\n",
      "235/235 [==============================] - 0s 713us/step - loss: 0.6425 - acc: 0.6596\n",
      "Epoch 97/100\n",
      "235/235 [==============================] - 0s 793us/step - loss: 0.6423 - acc: 0.6596\n",
      "Epoch 98/100\n",
      "235/235 [==============================] - 0s 746us/step - loss: 0.6420 - acc: 0.6596\n",
      "Epoch 99/100\n",
      "235/235 [==============================] - 0s 782us/step - loss: 0.6418 - acc: 0.6596\n",
      "Epoch 100/100\n",
      "235/235 [==============================] - 0s 771us/step - loss: 0.6415 - acc: 0.6596\n",
      "0.6610169491525424\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(2, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model.fit(X_train[:, :, np.newaxis], y_train, epochs=100)\n",
    "y_pred = model.predict(X_test[:, :, np.newaxis])\n",
    "print(accuracy_score(y_test, y_pred > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "205/205 [==============================] - 7s 36ms/step - loss: 0.6901 - acc: 0.5317\n",
      "Epoch 2/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6871 - acc: 0.6293\n",
      "Epoch 3/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6848 - acc: 0.6341\n",
      "Epoch 4/100\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.6824 - acc: 0.6488\n",
      "Epoch 5/100\n",
      "205/205 [==============================] - 1s 6ms/step - loss: 0.6800 - acc: 0.6585\n",
      "Epoch 6/100\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.6778 - acc: 0.6683\n",
      "Epoch 7/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6758 - acc: 0.6634\n",
      "Epoch 8/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6737 - acc: 0.6634\n",
      "Epoch 9/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6721 - acc: 0.6634\n",
      "Epoch 10/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6700 - acc: 0.6634\n",
      "Epoch 11/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6681 - acc: 0.6634\n",
      "Epoch 12/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6666 - acc: 0.6634\n",
      "Epoch 13/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6652 - acc: 0.6634\n",
      "Epoch 14/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6635 - acc: 0.6634\n",
      "Epoch 15/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6621 - acc: 0.6634\n",
      "Epoch 16/100\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.6609 - acc: 0.6634\n",
      "Epoch 17/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6595 - acc: 0.6634\n",
      "Epoch 18/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6583 - acc: 0.6634\n",
      "Epoch 19/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6570 - acc: 0.6634\n",
      "Epoch 20/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6559 - acc: 0.6634\n",
      "Epoch 21/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6547 - acc: 0.6634\n",
      "Epoch 22/100\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.6537 - acc: 0.6634\n",
      "Epoch 23/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6526 - acc: 0.6634\n",
      "Epoch 24/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6516 - acc: 0.6634\n",
      "Epoch 25/100\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.6507 - acc: 0.6634\n",
      "Epoch 26/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6499 - acc: 0.6634\n",
      "Epoch 27/100\n",
      "205/205 [==============================] - 1s 6ms/step - loss: 0.6489 - acc: 0.6634\n",
      "Epoch 28/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6481 - acc: 0.6634\n",
      "Epoch 29/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6472 - acc: 0.6634\n",
      "Epoch 30/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6464 - acc: 0.6634\n",
      "Epoch 31/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6457 - acc: 0.6634\n",
      "Epoch 32/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6450 - acc: 0.6634\n",
      "Epoch 33/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6445 - acc: 0.6634\n",
      "Epoch 34/100\n",
      "205/205 [==============================] - 1s 6ms/step - loss: 0.6438 - acc: 0.6634\n",
      "Epoch 35/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6434 - acc: 0.6634\n",
      "Epoch 36/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6428 - acc: 0.6634\n",
      "Epoch 37/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6422 - acc: 0.6634\n",
      "Epoch 38/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6417 - acc: 0.6634\n",
      "Epoch 39/100\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.6413 - acc: 0.6634\n",
      "Epoch 40/100\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.6408 - acc: 0.6634\n",
      "Epoch 41/100\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.6404 - acc: 0.6634\n",
      "Epoch 42/100\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.6400 - acc: 0.6634\n",
      "Epoch 43/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6397 - acc: 0.6634\n",
      "Epoch 44/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6393 - acc: 0.6634\n",
      "Epoch 45/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6390 - acc: 0.6634\n",
      "Epoch 46/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6386 - acc: 0.6634\n",
      "Epoch 47/100\n",
      "205/205 [==============================] - 1s 5ms/step - loss: 0.6384 - acc: 0.6634\n",
      "Epoch 48/100\n",
      "205/205 [==============================] - 1s 2ms/step - loss: 0.6380 - acc: 0.6634\n",
      "Epoch 49/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6378 - acc: 0.6634\n",
      "Epoch 50/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6375 - acc: 0.6634\n",
      "Epoch 51/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6373 - acc: 0.6634\n",
      "Epoch 52/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6372 - acc: 0.6634\n",
      "Epoch 53/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6370 - acc: 0.6634\n",
      "Epoch 54/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6367 - acc: 0.6634\n",
      "Epoch 55/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6365 - acc: 0.6634\n",
      "Epoch 56/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6363 - acc: 0.6634\n",
      "Epoch 57/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6361 - acc: 0.6634\n",
      "Epoch 58/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6360 - acc: 0.6634\n",
      "Epoch 59/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6358 - acc: 0.6634\n",
      "Epoch 60/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6356 - acc: 0.6634\n",
      "Epoch 61/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6355 - acc: 0.6634\n",
      "Epoch 62/100\n",
      "205/205 [==============================] - 1s 4ms/step - loss: 0.6353 - acc: 0.6634\n",
      "Epoch 63/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6352 - acc: 0.6634\n",
      "Epoch 64/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6351 - acc: 0.6634\n",
      "Epoch 65/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6350 - acc: 0.6634\n",
      "Epoch 66/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6349 - acc: 0.6634\n",
      "Epoch 67/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6348 - acc: 0.6634\n",
      "Epoch 68/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6347 - acc: 0.6634\n",
      "Epoch 69/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6346 - acc: 0.6634\n",
      "Epoch 70/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6345 - acc: 0.6634\n",
      "Epoch 71/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6343 - acc: 0.6634\n",
      "Epoch 72/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6342 - acc: 0.6634\n",
      "Epoch 73/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6341 - acc: 0.6634\n",
      "Epoch 74/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6340 - acc: 0.6634\n",
      "Epoch 75/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6339 - acc: 0.6634\n",
      "Epoch 76/100\n",
      "205/205 [==============================] - 1s 2ms/step - loss: 0.6338 - acc: 0.6634\n",
      "Epoch 77/100\n",
      "205/205 [==============================] - 1s 2ms/step - loss: 0.6337 - acc: 0.6634\n",
      "Epoch 78/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6336 - acc: 0.6634\n",
      "Epoch 79/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6335 - acc: 0.6634\n",
      "Epoch 80/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6334 - acc: 0.6634\n",
      "Epoch 81/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6333 - acc: 0.6634\n",
      "Epoch 82/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6332 - acc: 0.6634\n",
      "Epoch 83/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6331 - acc: 0.6634\n",
      "Epoch 84/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6330 - acc: 0.6634\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6329 - acc: 0.6634\n",
      "Epoch 86/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6328 - acc: 0.6634\n",
      "Epoch 87/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6328 - acc: 0.6634\n",
      "Epoch 88/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6327 - acc: 0.6634\n",
      "Epoch 89/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6326 - acc: 0.6634\n",
      "Epoch 90/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6325 - acc: 0.6634\n",
      "Epoch 91/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6323 - acc: 0.6634\n",
      "Epoch 92/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6322 - acc: 0.6634\n",
      "Epoch 93/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6322 - acc: 0.6634\n",
      "Epoch 94/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6320 - acc: 0.6634\n",
      "Epoch 95/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6319 - acc: 0.6634\n",
      "Epoch 96/100\n",
      "205/205 [==============================] - 1s 3ms/step - loss: 0.6319 - acc: 0.6634\n",
      "Epoch 97/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6317 - acc: 0.6634\n",
      "Epoch 98/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6317 - acc: 0.6634\n",
      "Epoch 99/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6316 - acc: 0.6634\n",
      "Epoch 100/100\n",
      "205/205 [==============================] - 0s 2ms/step - loss: 0.6316 - acc: 0.6634\n",
      "0.651685393258427\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, GRU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(3, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model.fit(X_train[:, :, np.newaxis], y_train, epochs=100)\n",
    "y_pred = model.predict(X_test[:, :, np.newaxis])\n",
    "print(accuracy_score(y_test, y_pred > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "235/235 [==============================] - 4s 16ms/step - loss: 0.6854 - acc: 0.5745\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6833 - acc: 0.5957\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6816 - acc: 0.6170\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6797 - acc: 0.6340\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6779 - acc: 0.6468\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6762 - acc: 0.6426\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6742 - acc: 0.6383\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.6725 - acc: 0.6426\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6706 - acc: 0.6298\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6688 - acc: 0.6340\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6670 - acc: 0.6468\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6652 - acc: 0.6468\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6632 - acc: 0.6426\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6615 - acc: 0.6426\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6597 - acc: 0.6511\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.6576 - acc: 0.6553\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.6559 - acc: 0.6553\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.6541 - acc: 0.6511\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6525 - acc: 0.6511\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6509 - acc: 0.6468\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6490 - acc: 0.6511\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6473 - acc: 0.6511\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6456 - acc: 0.6468\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6442 - acc: 0.6468\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6431 - acc: 0.6553\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6417 - acc: 0.6553\n",
      "Epoch 27/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6405 - acc: 0.6553\n",
      "Epoch 28/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6395 - acc: 0.6553\n",
      "Epoch 29/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6388 - acc: 0.6553\n",
      "Epoch 30/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.6376 - acc: 0.6553\n",
      "Epoch 31/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6369 - acc: 0.6553\n",
      "Epoch 32/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6363 - acc: 0.6553\n",
      "Epoch 33/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6357 - acc: 0.6553\n",
      "Epoch 34/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6353 - acc: 0.6553\n",
      "Epoch 35/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6350 - acc: 0.6553\n",
      "Epoch 36/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6345 - acc: 0.6553\n",
      "Epoch 37/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6343 - acc: 0.6553\n",
      "Epoch 38/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6342 - acc: 0.6553\n",
      "Epoch 39/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6339 - acc: 0.6553\n",
      "Epoch 40/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6338 - acc: 0.6553\n",
      "Epoch 41/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6336 - acc: 0.6553\n",
      "Epoch 42/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.6335 - acc: 0.6553\n",
      "Epoch 43/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.6334 - acc: 0.6553\n",
      "Epoch 44/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6333 - acc: 0.6553\n",
      "Epoch 45/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6332 - acc: 0.6553\n",
      "Epoch 46/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6331 - acc: 0.6553\n",
      "Epoch 47/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6331 - acc: 0.6553\n",
      "Epoch 48/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6329 - acc: 0.6553\n",
      "Epoch 49/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6328 - acc: 0.6553\n",
      "Epoch 50/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6327 - acc: 0.6553\n",
      "Epoch 51/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6327 - acc: 0.6553\n",
      "Epoch 52/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6327 - acc: 0.6553\n",
      "Epoch 53/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6326 - acc: 0.6553\n",
      "Epoch 54/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6325 - acc: 0.6553\n",
      "Epoch 55/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6325 - acc: 0.6553\n",
      "Epoch 56/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6325 - acc: 0.6553\n",
      "Epoch 57/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6325 - acc: 0.6553\n",
      "Epoch 58/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6323 - acc: 0.6553\n",
      "Epoch 59/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6323 - acc: 0.6553\n",
      "Epoch 60/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6322 - acc: 0.6553\n",
      "Epoch 61/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6322 - acc: 0.6553\n",
      "Epoch 62/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6322 - acc: 0.6553\n",
      "Epoch 63/100\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.6323 - acc: 0.6553\n",
      "Epoch 64/100\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.6322 - acc: 0.6553\n",
      "Epoch 65/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6321 - acc: 0.6553\n",
      "Epoch 66/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6321 - acc: 0.6596\n",
      "Epoch 67/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6322 - acc: 0.6596\n",
      "Epoch 68/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6321 - acc: 0.6596\n",
      "Epoch 69/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6321 - acc: 0.6596\n",
      "Epoch 70/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6319 - acc: 0.6596\n",
      "Epoch 71/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6319 - acc: 0.6596\n",
      "Epoch 72/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6320 - acc: 0.6596\n",
      "Epoch 73/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6319 - acc: 0.6596\n",
      "Epoch 74/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6318 - acc: 0.6596\n",
      "Epoch 75/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6318 - acc: 0.6596\n",
      "Epoch 76/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6317 - acc: 0.6553\n",
      "Epoch 77/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6317 - acc: 0.6553\n",
      "Epoch 78/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6318 - acc: 0.6553\n",
      "Epoch 79/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6316 - acc: 0.6596\n",
      "Epoch 80/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6317 - acc: 0.6596\n",
      "Epoch 81/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6317 - acc: 0.6553\n",
      "Epoch 82/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6316 - acc: 0.6553\n",
      "Epoch 83/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6316 - acc: 0.6553\n",
      "Epoch 84/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6317 - acc: 0.6553\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6315 - acc: 0.6553\n",
      "Epoch 86/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6315 - acc: 0.6553\n",
      "Epoch 87/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6315 - acc: 0.6553\n",
      "Epoch 88/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6314 - acc: 0.6553\n",
      "Epoch 89/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6314 - acc: 0.6596\n",
      "Epoch 90/100\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.6313 - acc: 0.6596\n",
      "Epoch 91/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6313 - acc: 0.6553\n",
      "Epoch 92/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6312 - acc: 0.6553\n",
      "Epoch 93/100\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.6311 - acc: 0.6553\n",
      "Epoch 94/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6312 - acc: 0.6596\n",
      "Epoch 95/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6311 - acc: 0.6596\n",
      "Epoch 96/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6310 - acc: 0.6596\n",
      "Epoch 97/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6310 - acc: 0.6596\n",
      "Epoch 98/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6310 - acc: 0.6553\n",
      "Epoch 99/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6310 - acc: 0.6511\n",
      "Epoch 100/100\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6309 - acc: 0.6511\n",
      "0.6610169491525424\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(2, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model.fit(X_train[:, :, np.newaxis], y_train, epochs=100)\n",
    "y_pred = model.predict(X_test[:, :, np.newaxis])\n",
    "print(accuracy_score(y_test, y_pred > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/TF/lib/python3.7/site-packages/sklearn/model_selection/_search.py:921: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected simple_rnn_3_input to have 3 dimensions, but got array with shape (294, 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d7b7007c4e79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/TF/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/TF/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/TF/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/TF/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/TF/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/TF/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/TF/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected simple_rnn_3_input to have 3 dimensions, but got array with shape (294, 25)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(2, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "#model.fit(X_train[:, :, np.newaxis], y_train, epochs=100)\n",
    "#    y_pred = model.predict(X_test[:, :, np.newaxis])\n",
    "    \n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.651685393258427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    ")\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
